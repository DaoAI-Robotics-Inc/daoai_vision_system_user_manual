案例分析
===========

.. content::
    :local:

拍摄金属件时，为了保持点云质量，RBG图片亮度低怎么办？
-------------------------------------------------------

    .. image:: images/case_pcc.png
        :scale: 70%

如上图，设置了相机参数为暗一点的时候，点云质量会更好，可是图片过暗，边缘匹配时无法正确的匹配到边缘。这种情况该怎么办呢？

可以在相机参数中，启用点云颜色（Point Cloud Color）功能，并调试曝光参数并采集验证。该功能会在采图时额外采集一张图片作为点云和RGB图片的颜色。该亮度可以独立设置，不会影响点云的质量。

    .. image:: images/point_cloud_color.png
        :scale: 70%

这样就可以在保持点云质量不变的同时，增加RGB图像的亮度，以更好的进行2D边缘匹配。


物体旋转180°后抓不准该怎么办？
----------------------------------

您首先可以考虑多加几个示教点位使用 **多示教抓取** ：

    .. image:: images/multi_pose_pick.png
        :scale: 70%

比如说您可以对于1个物体创建4个示教点位，每次示教 物体旋转90°

这样您就有了4个物体的旋转区间对应的抓取点位，系统自带的cluster picking 功能，会智能采用对应旋转区间的示教关系来执行抓取。


如果多示教抓取还不够，您可以考虑以下几点。

对抓取精度影响的主要因素有：
    1. 手眼标定精度
    2. 检测精度
    3. TCP精度
    4. 示教关系精度

那么改善的方面也应该从这几点下手

1. **检查手眼标定**

    手眼标定时，校准版的 **位置** 应该涵盖物体可能出现的位置。
    手眼标定时，校准版的 **旋转角度** 应该涵盖物体可能出现的旋转角度。

    如果手眼标定没有满足以上的两个条件，请重新做手眼标定。
    
2. **检测精度**

    查看物体的匹配情况，可以在快速检测步骤观察物体的坐标，以及点云的对齐情况，如果有误差的话，

        a. 优化相机配置 
        b. 优化深度学习模型
        c. 优化点云模型
        d. 优化高级检测参数

3. **TCP精度**

    通常长夹爪在遇到物体检测的角度误差时，平移误差会根据夹爪的长度成比增加。那么为了减少这个问题，就需要缩短示教关系的距离 （tool in object）。

    如果机器人是用法兰位置交互的，那么请尝试创建一个TCP(tool center point)并使用TCP来进行示教、抓取。

    .. image:: images/tcp.png
        :scale: 60%


4. **示教关系精度**

    与3.同理，尽可能地缩短示教点与物体坐标原点的距离，这样可以减少误差。
    
    如果您示教完成后，发现TCP的点位 在虚拟现实中和 想要的抓取点位有些许误差，那么可以尝试在显示窗口里，将TCP调整至理想抓取点位。这样可以减少示教时的误差。
    
    .. image:: images/pick_pose.png
        :scale: 60%